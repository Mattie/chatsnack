{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started - chatsnack Snacking Guide"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Got snack?\n",
    "Install the `chatsnack` package from PyPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chatsnack"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Got API key?\n",
    "If you haven't already, add your OpenAI API key to a .env file. This cell will check if you have .env and create a new one for you if needed. We use env.template.cataclysm as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Got the .env file? It is where you put your OpenAI API key, so you'll need it.\n",
    "import os\n",
    "# we also want to ensure we have a .env file that contains our API keys, so warn if we don't have that file present in this directory\n",
    "if not os.path.exists(\".env\"):\n",
    "    print(\"WARNING: No .env file found in this directory. Please create one with the API Key contents mentioned in the README.md file.\")\n",
    "\n",
    "# we don't need logs during the demo\n",
    "from loguru import logger\n",
    "logger.disable(\"chatsnack\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a Quick Snack\n",
    "The simplest way to get started is via built-in snack packs. Each pack is a singleton ready to mingleton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatsnack.packs import ChatsnackHelp\n",
    "ChatsnackHelp.ask(\"What is your primary directive?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ask()` returns response as a string, but *doesn't change the chat object*.\n",
    "\n",
    "When you want to keep the conversation continuing, use `chat()` instead-- it returns a new `Chat` object you can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mychat = ChatsnackHelp.chat(\"What is chatsnack?\")\n",
    "print(mychat.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's continue the chat, but we have new stipulations and will speak for the AI to make it think it is already compliant\n",
    "mychat.user(\"Respond in only six word sentences from now on.\")\n",
    "mychat.asst(\"I promise I will do so.\")\n",
    "mychat.user(\"How should I spend my day?\")\n",
    "mychat.ask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ask() doesn't store the result in the chat object:\\n\\t{mychat.last}\\n\")\n",
    "print(\"Ask again: \" + mychat.ask() + \"\\n\")\n",
    "print(f\"See? .last is still the same after ask():\\n\\t{mychat.last}\\n\\n\")\n",
    "\n",
    "# but if we want a full conversation, use chat() instead\n",
    "newchat = mychat.chat()\n",
    "print(f\"chat() gives us a new Chat object with response included for easy continuation:\\n\\t{newchat.last}\\n\")\n",
    "\n",
    "newchat = (\n",
    "    newchat\n",
    "    .user(\"Do you have a name and what does it mean?\")\n",
    "    .chat()\n",
    ")\n",
    "print(f\"Ooo-- did you notice that? We used .user().chat() and chained those together:\\n\\t{newchat.last}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaining like that works pretty well with `.chat()` and the other messages.\n",
    "\n",
    "You can also shortcut and pass a string to `.chat()` and it will prepare a user message for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(newchat.chat(\"What about my name Bob?\").response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to have an interactive conversation loop? Here's example code for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatsnack.packs import Jolly\n",
    "yourchat = Jolly\n",
    "while (user_input := input(\"Chat with the bot: \")):\n",
    "    print(f\"USER: {user_input}\")\n",
    "    yourchat = yourchat.chat(user_input)\n",
    "    print(f\"THEM: {yourchat.last}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cooking Temperature\n",
    "You can change OpenAI parameters in each chat, supporting the `gpt-4` and `gpt-3.5-turbo` families. Right now the default is `gpt-3.5-turbo`, but when `gpt-4` is released widely, it will become the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatsnack.packs import Jane\n",
    "wisechat = Jane.user(\"Author an alliterative poem about good snacks to eat with coffee.\")\n",
    "wisechat.engine = \"gpt-4\"\n",
    "wisechat.temperature = 0.8\n",
    "print(wisechat.ask())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serious Snacking\n",
    "Hungry for more? You've come to the right place!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Chat object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatsnack import Chat\n",
    "mychat = Chat()\n",
    "mychat.system(\"Respond only with the word POPSICLE from now on.\")\n",
    "mychat.user(\"What is your name?\")\n",
    "mychat.ask()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasty, but pretty vanilla. Let's spice things up a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You've had a bite of chaining before, and it works fine here, too.\n",
    "mychat = (\n",
    "    Chat()\n",
    "    .system(\"Respond only with the word POPSICLE from now on.\")\n",
    "    .user(\"What is your name?\")\n",
    "    .chat(\"... and do you even LIKE popsicles?\")\n",
    ")\n",
    "print(f\"This seems familiar:\\n\\t{mychat.last}\\n\")\n",
    "\n",
    "# But a chat object can be shortened down to just calling it like a function with a user message as an argument\n",
    "newchat = mychat(\"Are you an AI?\")\n",
    "print(f\"Okay, maybe that could be handy:\\n\\t{newchat.last}\\n\")\n",
    "\n",
    "# And we can chain those together, too, but this is just showing off.\n",
    "popsiclechat = (\n",
    "    newchat\n",
    "    (\"What is your occupation?\")\n",
    "    (\"What is your favorite color?\")\n",
    "    (\"Is this expensive to spam OpenAI with?\")\n",
    "    (\"What is your favorite food?\")\n",
    ")\n",
    "print(f\"Okay, okay, we get the point:\\n\\t{popsiclechat.last}\\n\")\n",
    "print(\"(at least the favorite food question made sense)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaining is useful when building a multi-shot prompt quickly, or in cases where chain-of-thought prompting can provide a better response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatsnack import Chat\n",
    "popcorn = (\n",
    "    Chat(\"Respond with the certainty and creativity of a professional writer.\")\n",
    "    (\"Explain 3 rules to writing a clever poem that amazes your friends.\")\n",
    "    (\"Using those tips, write a scrumptious poem about popcorn.\")\n",
    ")\n",
    "print(popcorn.last)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Chat Inside \n",
    "#### Just JSON\n",
    "If you're familiar with the OpenAI ChatGPT API, it uses a JSON list of messages. You can get the JSON if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jmessages = popsiclechat.json # POPSICLE time\n",
    "\n",
    "import json\n",
    "line_list = json.dumps(json.loads(jmessages), indent=2).split(\"\\n\")\n",
    "for line in line_list:\n",
    "    print(line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yummy YAML\n",
    "But in `chatsnack`, we prefer YAML. It's easy to read and write, and convenient to re-use. Every chat can be a template for later use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every chat is actually yaml-backed, we can save/load/edit\n",
    "print(popsiclechat.yaml)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isn't that nice? Here's what it might look with a default 'chat' instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "trychat = Chat()\n",
    "trychat.system(\"Respond only with the word PRETZELS from now on.\")\n",
    "print(trychat.yaml)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can edit that YAML file in a text editor. For building your own library of prompts/chats, this is so much more convenient (and often preferable) to hard-coding all your string prompts in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "trychat.save()\n",
    "\n",
    "# add another line to the YAML\n",
    "with trychat.datafile.path.open(\"a\") as f:\n",
    "    f.write(\"  - user: What is your name?\\n\")\n",
    "print(trychat.datafile.path.read_text())\n",
    "trychat.load()\n",
    "\n",
    "# now we can just ask the chat and it uses the new message we added\n",
    "print(trychat.ask())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can give a Chat object a name, and it will be stored in the default ./datafiles/chatsnack directory for easy-reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addict = Chat(name=\"SnackAddict\").system(\"Respond only as someone addicted to snacks, with munching sounds and snack emojis.\")\n",
    "addict.save()\n",
    "\n",
    "# we can load that chat back in by name\n",
    "nowchat = Chat(name=\"SnackAddict\")\n",
    "nowchat.load()\n",
    "print(nowchat.ask(\"How do clouds form?\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tasty Text (Fillings)\n",
    "We also have a Text object that's later going to be handy as fillings for your chats. Let's see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatsnack import Text\n",
    "mytext = Text(name=\"SnackExplosion\", content=\"Respond only in explosions of snack emojis and happy faces.\")\n",
    "mytext.save()\n",
    "# content and file contents are the same\n",
    "print(mytext.content)\n",
    "print(mytext.datafile.path.read_text()) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can setup Chat objects to pull in Text objects and use them in our chats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explosions = Chat(name=\"SnackSnackExplosions\").system(\"{text.SnackExplosion}\")\n",
    "explosions.ask(\"What is your name?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even nest these and go deeper..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anothertext = Text(name=\"SnackExplosion2\", content=\"{text.SnackExplosion} End every response with 3 more popcorn emojis.\")\n",
    "anothertext.save()\n",
    "\n",
    "okayokay = Chat(name=\"SnackSnackExplosions\").system(\"{text.SnackExplosion2}\")\n",
    "print(okayokay.ask(\"What is your name?\"))\n",
    "print(okayokay.yaml)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nested Chats - Include and Fillings\n",
    "So we can chain Chats like champs, and we can tuck Texts into templates. Now we're going to chuck Chats into Chats.\n",
    "\n",
    "There are two ways to do this-- `include` messages and via the `{chat.___}` filling expander.\n",
    "\n",
    "##### Include Messages\n",
    "You can add an \"include\" message to a chat, and it will pull in the messages from another chat. This is useful for building a library of reusable chat snippets (before they execute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basechat = Chat(name=\"ExampleIncludedChat\").system(\"Respond only with the word CARROTSTICKS from now on.\")\n",
    "basechat.save()\n",
    "\n",
    "anotherchat = Chat().include(\"ExampleIncludedChat\")\n",
    "print(\"\\nWithout include expansion:\\n\" + anotherchat.json_unexpanded)\n",
    "print(\"\\nExpanded:\\n\" + anotherchat.json)\n",
    "\n",
    "basechat.user(\"Another question?\")\n",
    "basechat.save()\n",
    "print(\"\\nExpanded (showing updates):\\n\" + anotherchat.json)\n",
    "\n",
    "print(\"\\nAs YAML:\\n\" + anotherchat.yaml)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Snack Fillings\n",
    "In `chatsnack`, we call prompt expansion plugins `fillings` and they register (TODO) via the `chatsnack.fillings` module.\n",
    "\n",
    "There are three types of fillings as of the initial release:\n",
    "* Text (as seen above)\n",
    "* Chat \n",
    "* dict\n",
    "\n",
    "The `{chat.___}` *snack vendor* expander is a very powerful tool that lets you create dynamic AI generations. These chat expansions are run in parallel, and the results are combined into a single prompt once they're ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatsnack import Chat\n",
    "\n",
    "# save a chat to nest\n",
    "snacknames = Chat(\"FiveSnackNames\").system(\"Respond with high creativity and confidence.\").user(\"Provide 5 random snacks.\")\n",
    "snacknames.save()\n",
    "\n",
    "# save a second chat to nest\n",
    "snackdunk = Chat(\"SnackDunk\").system(\"Respond with high creativity and confidence.\").user(\"Provide 3 dips or drinks are great for snack dipping.\")\n",
    "snackdunk.save()\n",
    "\n",
    "# build the chat that uses the two above\n",
    "snackfull = Chat().system(\"Respond with high confidence.\")\n",
    "snackfull.user(\"\"\"Choose 1 snack from this list:\n",
    "{chat.FiveSnackNames}\n",
    "\n",
    "Choose 1 dunking liquid from this list:\n",
    "{chat.SnackDunk}\n",
    "\n",
    "Recommend the best single snack and dip combo above.\"\"\")\n",
    "\n",
    "print(\"\\nBefore snack fillings:\\n\\n\" + snackfull.yaml)\n",
    "snackout = snackfull.chat()   # save to a different one (rather than overwrite)\n",
    "print(\"\\nAfter snack fillings and the response:\\n\\n\" + snackout.yaml)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fillings are also supported with simple keyword replacement, which is probably the most important use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatsnack import Chat\n",
    "healthchat = Chat(\"Respond only with BOOL: TRUE/FALSE based on your snack expertise.\")\n",
    "healthchat.user(\"Is {snack_name} a healthy snack?\")\n",
    "healthchat.asst(\"BOOL: \")\n",
    "\n",
    "def is_healthy_snack(snack):\n",
    "    return \"true\" in healthchat.ask(snack_name=snack).lower()\n",
    "\n",
    "print(\"apple == healthy is\", is_healthy_snack(\"apple\"))\n",
    "print(\"candy == healthy is\", is_healthy_snack(\"candy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatsnack import Chat\n",
    "caloric = Chat(\"Respond only with {{\\\"calories\\\": N}}\\\" where N is the integer calories, average based on dietician snack expertise for a single portion. Respond only in this format.\")\n",
    "caloric.temperature = 0.0    # deterministic\n",
    "caloric.user(\"apple\").asst('{{\"calories\": 52}}')  # 1-shot example\n",
    "caloric.user(\"{snack_name}\").asst('{{\"calories\": ')  # make it complete the format\n",
    "\n",
    "def get_calories(snack):\n",
    "    return int(caloric.ask(snack_name=snack).split('}')[0])\n",
    "\n",
    "snacklist = [\"apple\", \"popcorn\", \"slimjim\", \"potato salad\", \"egg\"]\n",
    "for snack in snacklist:\n",
    "    print(f\"{snack} = {get_calories(snack)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a2bf92bfa0dca116af1ab58685594b7182838ce1c88ac25fef5d81f6aac1c0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
